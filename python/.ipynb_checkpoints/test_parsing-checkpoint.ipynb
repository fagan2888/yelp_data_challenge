{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Read data file into a python array\n",
    "with open('../data/test_tip.json', 'rb') as f:\n",
    "    bus_data = f.readlines()\n",
    "\n",
    "# remove the trailing \"\\n\" from each line\n",
    "bus_data = map(lambda x: x.rstrip(), bus_data)\n",
    "# put individual business JSON objects into list\n",
    "data_json = \"[\" + ','.join(bus_data) + \"]\"\n",
    "\n",
    "# Create pandas df\n",
    "bus_df = pd.read_json(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>2013-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Don't waste your time.</td>\n",
       "      <td>tip</td>\n",
       "      <td>-6rEfobYjMxpUWLNxszaxQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Your GPS will not allow you to find this place...</td>\n",
       "      <td>tip</td>\n",
       "      <td>EZ0r9dKKtEGVx2CdnowPCw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>0</td>\n",
       "      <td>Great drink specials!</td>\n",
       "      <td>tip</td>\n",
       "      <td>xb6zEQCw9I-Gl0g06e1KsQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>0</td>\n",
       "      <td>Friendly staff, good food, great beer selectio...</td>\n",
       "      <td>tip</td>\n",
       "      <td>QawZN4PSW7ng_9SP7pjsVQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_lU0-eSWJCRvNGk78Zh9Q</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>0</td>\n",
       "      <td>Beautiful restoration.</td>\n",
       "      <td>tip</td>\n",
       "      <td>MLQre1nvUtW-RqMTc4iC9A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_lU0-eSWJCRvNGk78Zh9Q</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>Home to Stage 62 theatre group.</td>\n",
       "      <td>tip</td>\n",
       "      <td>bvu13GyOUwhEjPum2xjiqQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_qopVQ6_Mz6W7-Pmbi56GQ</td>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>A God send if you're not a gear head!</td>\n",
       "      <td>tip</td>\n",
       "      <td>bvu13GyOUwhEjPum2xjiqQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_qopVQ6_Mz6W7-Pmbi56GQ</td>\n",
       "      <td>2010-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>Great people ... great service ... always busy</td>\n",
       "      <td>tip</td>\n",
       "      <td>_QFom7aSHKNCDsNXKd-3xQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wJr6kSA5dchdgOdwH6dZ2w</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarah rocks! Best waitress here! Be sure to ge...</td>\n",
       "      <td>tip</td>\n",
       "      <td>fvTivrsJoUMYXnOJw9wZfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cdcus0NADzyY3XiJM2O5Sg</td>\n",
       "      <td>2011-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Unleaded 3.42</td>\n",
       "      <td>tip</td>\n",
       "      <td>bvu13GyOUwhEjPum2xjiqQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date  likes  \\\n",
       "0  cE27W9VPgO88Qxe4ol6y_g 2013-04-18      0   \n",
       "1  mVHrayjG3uZ_RLHkLj-AMg 2013-01-06      1   \n",
       "2  KayYbHCt-RkbGcPdGOThNg 2013-12-03      0   \n",
       "3  KayYbHCt-RkbGcPdGOThNg 2015-07-08      0   \n",
       "4  1_lU0-eSWJCRvNGk78Zh9Q 2015-10-25      0   \n",
       "5  1_lU0-eSWJCRvNGk78Zh9Q 2015-01-06      0   \n",
       "6  _qopVQ6_Mz6W7-Pmbi56GQ 2013-02-13      0   \n",
       "7  _qopVQ6_Mz6W7-Pmbi56GQ 2010-08-27      0   \n",
       "8  wJr6kSA5dchdgOdwH6dZ2w 2013-07-22      0   \n",
       "9  Cdcus0NADzyY3XiJM2O5Sg 2011-10-12      0   \n",
       "\n",
       "                                                text type  \\\n",
       "0                             Don't waste your time.  tip   \n",
       "1  Your GPS will not allow you to find this place...  tip   \n",
       "2                              Great drink specials!  tip   \n",
       "3  Friendly staff, good food, great beer selectio...  tip   \n",
       "4                             Beautiful restoration.  tip   \n",
       "5                    Home to Stage 62 theatre group.  tip   \n",
       "6              A God send if you're not a gear head!  tip   \n",
       "7     Great people ... great service ... always busy  tip   \n",
       "8  Sarah rocks! Best waitress here! Be sure to ge...  tip   \n",
       "9                                      Unleaded 3.42  tip   \n",
       "\n",
       "                  user_id  \n",
       "0  -6rEfobYjMxpUWLNxszaxQ  \n",
       "1  EZ0r9dKKtEGVx2CdnowPCw  \n",
       "2  xb6zEQCw9I-Gl0g06e1KsQ  \n",
       "3  QawZN4PSW7ng_9SP7pjsVQ  \n",
       "4  MLQre1nvUtW-RqMTc4iC9A  \n",
       "5  bvu13GyOUwhEjPum2xjiqQ  \n",
       "6  bvu13GyOUwhEjPum2xjiqQ  \n",
       "7  _QFom7aSHKNCDsNXKd-3xQ  \n",
       "8  fvTivrsJoUMYXnOJw9wZfw  \n",
       "9  bvu13GyOUwhEjPum2xjiqQ  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : [u\"n't wast time\", u'gps allow find place put rankin polic depart instead direct across street', u'great drink special', u'friend staff good food great beer select relax atmospher', u'beauti restor', u'home stage 62 theatr group', u'god send re gear head', u'great peopl great servic alway busi', u'sarah rock best waitress sure get compliment glass', u'unlead 342']\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for normalising text data\n",
    "\n",
    "# Convert all words to lowercase, remove punctuation, tokenise and stem\n",
    "# and remove stopwords, threshold = 10%\n",
    "def norm_corpus(document_list):\n",
    "    norm_doc_list = []\n",
    "    \n",
    "    # lowercase\n",
    "    document_list = [word.lower() for word in document_list]\n",
    "\n",
    "    \n",
    "    # remove symbols in text\n",
    "    symbols = \",.?!\"\n",
    "    for sym in symbols:\n",
    "        document_list = [word.replace(sym,'') for word in document_list]\n",
    "    \n",
    "    \n",
    "    # loop through each string i.e. review in the column\n",
    "    for doc in document_list:\n",
    "        doc = nltk.word_tokenize(doc)\n",
    "        \n",
    "        # remove stopwords\n",
    "        doc = [word for word in doc if word not in stopwords.words('english')]\n",
    "        \n",
    "        # stem words\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        doc = [stemmer.stem(word) for word in doc]\n",
    "        \n",
    "        # make tokenised text one string\n",
    "        norm_doc = \" \".join(doc)\n",
    "        norm_doc_list.append(norm_doc)\n",
    "    \n",
    "    return norm_doc_list\n",
    "\n",
    "print len(norm_corpus(bus_df.text)), \":\", norm_corpus(bus_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for vectorise normalised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({u'time': 1}),\n",
       " Counter({u'depart': 1, u'gps': 1, u'place': 1, u'street': 1}),\n",
       " Counter(),\n",
       " Counter({u'beer': 1, u'food': 1, u'select': 1, u'staff': 1}),\n",
       " Counter({u'beauti': 1, u'restor': 1}),\n",
       " Counter({u'group': 1, u'home': 1, u'stage': 1, u'theatr': 1}),\n",
       " Counter({u'head': 1, u're': 1, u'send': 1}),\n",
       " Counter({u'alway': 1, u'busi': 1, u'peopl': 1}),\n",
       " Counter({u'glass': 1, u'rock': 1, u'sarah': 1, u'waitress': 1}),\n",
       " Counter()]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorise keywords from normalised text to vector including only nouns and adjectives\n",
    "def review_vector(norm_doc_list):\n",
    "    review_list = []\n",
    "\n",
    "    # select all words categorised as nouns or adjectives\n",
    "    # loop through each string i.e. review in the df column\n",
    "    for doc in norm_doc_list:\n",
    "        review_keyword_list = []\n",
    "        doc = nltk.word_tokenize(doc)\n",
    "        # create tuple for each word in list: (word, tag)\n",
    "        token_category = nltk.pos_tag(doc)\n",
    "        \n",
    "        \n",
    "        for word, tag in token_category:    \n",
    "            \n",
    "            # nouns\n",
    "            if (tag == 'NN' or tag == 'NNS' or tag == 'NNP' or tag == 'NNPS'):\n",
    "                review_keyword_list.append(word)\n",
    "                \n",
    "            # adjectives\n",
    "            elif (tag == 'JJ' or tag == 'JJS' or tag == 'JJP' or tag == 'JJPS'):\n",
    "                review_vector_list.append(word)\n",
    "            else:\n",
    "                pass     \n",
    "        \n",
    "        review_keywords = \" \".join(review_keyword_list)\n",
    "        review_list.append(review_keywords)\n",
    "        \n",
    "        # vectorise string\n",
    "        WORD = re.compile(r'\\w+')\n",
    "        review_vector = [collections.Counter(WORD.findall(word)) for word in review_list]\n",
    "    \n",
    "    \n",
    "    return review_vector\n",
    "    \n",
    "# test = norm_corpus(bus_df.text)\n",
    "review_vector(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u\"n't\", 'RB'), (u'wast', 'JJ'), (u'time', 'NN')]\n",
      "[(u'gps', 'NN'), (u'allow', 'VB'), (u'find', 'JJ'), (u'place', 'NN'), (u'put', 'VBD'), (u'rankin', 'JJ'), (u'polic', 'JJ'), (u'depart', 'NN'), (u'instead', 'RB'), (u'direct', 'JJ'), (u'across', 'IN'), (u'street', 'NN')]\n",
      "[(u'great', 'JJ'), (u'drink', 'VBP'), (u'special', 'JJ')]\n",
      "[(u'friend', 'JJ'), (u'staff', 'NN'), (u'good', 'JJ'), (u'food', 'NN'), (u'great', 'JJ'), (u'beer', 'NN'), (u'select', 'NN'), (u'relax', 'VBZ'), (u'atmospher', 'RB')]\n",
      "[(u'beauti', 'NN'), (u'restor', 'NN')]\n",
      "[(u'home', 'NN'), (u'stage', 'NN'), (u'62', 'CD'), (u'theatr', 'NN'), (u'group', 'NN')]\n",
      "[(u'god', 'JJ'), (u'send', 'NN'), (u're', 'NN'), (u'gear', 'VBP'), (u'head', 'NN')]\n",
      "[(u'great', 'JJ'), (u'peopl', 'NN'), (u'great', 'JJ'), (u'servic', 'JJ'), (u'alway', 'NN'), (u'busi', 'NN')]\n",
      "[(u'sarah', 'NN'), (u'rock', 'NN'), (u'best', 'JJS'), (u'waitress', 'NN'), (u'sure', 'JJ'), (u'get', 'VB'), (u'compliment', 'JJ'), (u'glass', 'NN')]\n",
      "[(u'unlead', 'JJ'), (u'342', 'CD')]\n"
     ]
    }
   ],
   "source": [
    "# Vectorise keywords from normalised text to vector including only nouns and adjectives\n",
    "norm_doc_list = norm_corpus(bus_df.text)\n",
    "review_list = []\n",
    "\n",
    "    # select all words categorised as nouns or adjectives\n",
    "    # loop through each string i.e. review in the df column\n",
    "for doc in norm_doc_list:\n",
    "    review_keyword_list = []\n",
    "    doc = nltk.word_tokenize(doc)\n",
    "        # create tuple for each word in list: (word, tag)\n",
    "    token_category = nltk.pos_tag(doc)\n",
    "    \n",
    "    \n",
    "\n",
    "    print token_category\n",
    "        \n",
    "#         review_keywords = \" \".join(review_keyword_list)\n",
    "#         review_list.append(review_keywords)\n",
    "        \n",
    "#         # vectorise string\n",
    "#     WORD = re.compile(r'\\w+')\n",
    "#     review_vector = [collections.Counter(WORD.findall(word)) for word in review_list]\n",
    "    \n",
    "    \n",
    "#     return review_vector\n",
    "    \n",
    "# test = norm_corpus(bus_df.text)\n",
    "# review_vector(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
