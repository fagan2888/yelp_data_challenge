{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "import feather\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "# Read data file into a pandas dataframe\n",
    "read_df = feather.read_dataframe('../parsed_data/filtered_tip_data.feather', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = read_df.head(300)\n",
    "# type(bus_df.stars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for normalising text data\n",
    "\n",
    "# Convert all words to lowercase, remove punctuation, tokenise and stem\n",
    "# and remove stopwords, threshold = 10%\n",
    "def norm_corpus(document):\n",
    "    \n",
    "    # unicode decode\n",
    "    document = document.decode('utf-8')\n",
    "    \n",
    "    # lowercase and remove symbols\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    doc_tokens = tokenizer.tokenize(document.lower())\n",
    "        \n",
    "    # remove stopwords\n",
    "    doc_tokens = [word for word in doc_tokens if word not in stopwords.words('english')]\n",
    "        \n",
    "    # stem words\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    doc_stem = [stemmer.stem(word) for word in doc_tokens]\n",
    "        \n",
    "    # make tokenised text one string\n",
    "    norm_doc = \" \".join(doc_stem)\n",
    "    \n",
    "    return norm_doc\n",
    "\n",
    "\n",
    "# Vectorise keywords from normalised text to vector including only nouns and adjectives\n",
    "def review_vector(norm_doc):\n",
    "\n",
    "    # select all words categorised as nouns or adjectives\n",
    "    # loop through each string i.e. review in the df column\n",
    "    review_keyword_list = []\n",
    "    doc = nltk.word_tokenize(norm_doc)\n",
    "\n",
    "    # create tuple for each word in list: (word, tag)\n",
    "    token_category = nltk.pos_tag(doc)  \n",
    "\n",
    "    for word, tag in token_category:   \n",
    "            \n",
    "        # nouns\n",
    "        if (tag == 'NN' or tag == 'NNS' or tag == 'NNP' or tag == 'NNPS'):\n",
    "            review_keyword_list.append(word)\n",
    "                \n",
    "        # adjectives\n",
    "        elif (tag == 'JJ' or tag == 'JJS' or tag == 'JJP' or tag == 'JJPS'):\n",
    "            review_keyword_list.append(word)\n",
    "        \n",
    "        else:\n",
    "            pass     \n",
    "        \n",
    "    review_keywords = \" \".join(review_keyword_list)\n",
    "        \n",
    "    # vectorise string\n",
    "    WORD = re.compile(r'\\w+')\n",
    "    review_vector = Counter(WORD.findall(review_keywords))\n",
    "    \n",
    "    \n",
    "    return dict(review_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business_id',\n",
       " 'date',\n",
       " 'likes',\n",
       " 'text',\n",
       " 'type',\n",
       " 'user_id',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'name',\n",
       " 'city',\n",
       " 'stars',\n",
       " 'review_count',\n",
       " 'food_drink']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tip text normalised, next: vectorise\n"
     ]
    }
   ],
   "source": [
    "## Tip data\n",
    "output_df = test.ix[:,['business_id', 'date', 'likes', 'text', 'type',\n",
    "                       'user_id', 'latitude', 'longitude', 'name', 'city',\n",
    "                       'stars', 'review_count', 'food_drink']]\n",
    "output_df.text = test.text.apply(lambda x: norm_corpus(x))\n",
    "print \"tip text normalised, next: vectorise\"\n",
    "output_df.text = output_df.text.apply(lambda x: review_vector(x))\n",
    "\n",
    "## Review data\n",
    "# bus_df = bus_df[bus_df.stars > 3]\n",
    "# output_df = bus_df.ix[:,['business_id', 'user_id', 'date', 'stars', 'votes', 'text']]\n",
    "# output_df.text = output_df.text.apply(lambda x: norm_corpus(x))\n",
    "# print \"tip text normalised, next: vectorise\"\n",
    "# output_df.text = output_df.text.apply(lambda x: review_vector(x))\n",
    "# output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>food_drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wqu7ILomIOPSduRwoWp4AQ</td>\n",
       "      <td>2011-12-17</td>\n",
       "      <td>0</td>\n",
       "      <td>{u'grit': 1}</td>\n",
       "      <td>tip</td>\n",
       "      <td>bvu13GyOUwhEjPum2xjiqQ</td>\n",
       "      <td>40.391140</td>\n",
       "      <td>-80.073788</td>\n",
       "      <td>Denny's</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wqu7ILomIOPSduRwoWp4AQ</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>{u'hair': 1, u'second': 1, u'time': 2, u'food'...</td>\n",
       "      <td>tip</td>\n",
       "      <td>UxfFAw2-cTpeWvRROF1HEw</td>\n",
       "      <td>40.391140</td>\n",
       "      <td>-80.073788</td>\n",
       "      <td>Denny's</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wqu7ILomIOPSduRwoWp4AQ</td>\n",
       "      <td>2015-06-15</td>\n",
       "      <td>0</td>\n",
       "      <td>{u'food': 1, u'servic': 1, u'good': 1}</td>\n",
       "      <td>tip</td>\n",
       "      <td>Dmvqb5TVcfHq8TMW20zJww</td>\n",
       "      <td>40.391140</td>\n",
       "      <td>-80.073788</td>\n",
       "      <td>Denny's</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8Nm_jcCYtMXYW0ODSHDiXA</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>{u'food': 1, u'tri': 1, u'alll': 1, u'best': 1}</td>\n",
       "      <td>tip</td>\n",
       "      <td>geqTlvuRIXV3kUUVnx2zzA</td>\n",
       "      <td>40.440004</td>\n",
       "      <td>-80.090911</td>\n",
       "      <td>Sapporo Japanese Steakhouse</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_jsJFrAmFVPRio0eEVExbA</td>\n",
       "      <td>2013-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>{u'good': 1, u'mcd': 1, u'drive': 1, u'coffe':...</td>\n",
       "      <td>tip</td>\n",
       "      <td>_BV9_YrP3sQlNVzaJo2z_w</td>\n",
       "      <td>40.492067</td>\n",
       "      <td>-80.062350</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date  likes  \\\n",
       "0  wqu7ILomIOPSduRwoWp4AQ 2011-12-17      0   \n",
       "1  wqu7ILomIOPSduRwoWp4AQ 2014-04-27      0   \n",
       "2  wqu7ILomIOPSduRwoWp4AQ 2015-06-15      0   \n",
       "3  8Nm_jcCYtMXYW0ODSHDiXA 2015-05-13      0   \n",
       "4  _jsJFrAmFVPRio0eEVExbA 2013-02-02      0   \n",
       "\n",
       "                                                text type  \\\n",
       "0                                       {u'grit': 1}  tip   \n",
       "1  {u'hair': 1, u'second': 1, u'time': 2, u'food'...  tip   \n",
       "2             {u'food': 1, u'servic': 1, u'good': 1}  tip   \n",
       "3    {u'food': 1, u'tri': 1, u'alll': 1, u'best': 1}  tip   \n",
       "4  {u'good': 1, u'mcd': 1, u'drive': 1, u'coffe':...  tip   \n",
       "\n",
       "                  user_id   latitude  longitude                         name  \\\n",
       "0  bvu13GyOUwhEjPum2xjiqQ  40.391140 -80.073788                      Denny's   \n",
       "1  UxfFAw2-cTpeWvRROF1HEw  40.391140 -80.073788                      Denny's   \n",
       "2  Dmvqb5TVcfHq8TMW20zJww  40.391140 -80.073788                      Denny's   \n",
       "3  geqTlvuRIXV3kUUVnx2zzA  40.440004 -80.090911  Sapporo Japanese Steakhouse   \n",
       "4  _BV9_YrP3sQlNVzaJo2z_w  40.492067 -80.062350                   McDonald's   \n",
       "\n",
       "         city  stars  review_count  food_drink  \n",
       "0  Pittsburgh    4.0             9           1  \n",
       "1  Pittsburgh    4.0             9           1  \n",
       "2  Pittsburgh    4.0             9           1  \n",
       "3  Pittsburgh    4.5             7           1  \n",
       "4  Pittsburgh    2.0             6           1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Group by same month in year to count number of emails per topic\n",
    "## i.e. -> emails sent per topic monthly\n",
    "# make date column index\n",
    "output_df.index = pd.to_datetime(output_df.date, \n",
    "                                 format='%m/%d/%Y')\n",
    "\n",
    "# perform groupby, summinng up dummies for count\n",
    "monthly = pd.DataFrame.groupby(output_df, \n",
    "                               by=[output_df.index.year, \n",
    "                                   output_df.index.month]).aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feather.write_dataframe(new_df, '../parsed_data/parsed_tip_data.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df['test'] = {'test': dict(), 'also': dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test\n",
       "also  test\n",
       "test  also"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
