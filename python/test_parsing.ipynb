{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Read data file into a python array\n",
    "with open('../data/test_tip.json', 'rb') as f:\n",
    "    bus_data = f.readlines()\n",
    "\n",
    "# remove the trailing \"\\n\" from each line\n",
    "bus_data = map(lambda x: x.rstrip(), bus_data)\n",
    "# put individual business JSON objects into list\n",
    "data_json = \"[\" + ','.join(bus_data) + \"]\"\n",
    "\n",
    "# Create pandas df\n",
    "bus_df = pd.read_json(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>2013-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Don't waste your time.</td>\n",
       "      <td>tip</td>\n",
       "      <td>-6rEfobYjMxpUWLNxszaxQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Your GPS will not allow you to find this place...</td>\n",
       "      <td>tip</td>\n",
       "      <td>EZ0r9dKKtEGVx2CdnowPCw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>0</td>\n",
       "      <td>Great drink specials!</td>\n",
       "      <td>tip</td>\n",
       "      <td>xb6zEQCw9I-Gl0g06e1KsQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>0</td>\n",
       "      <td>Friendly staff, good food, great beer selectio...</td>\n",
       "      <td>tip</td>\n",
       "      <td>QawZN4PSW7ng_9SP7pjsVQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_lU0-eSWJCRvNGk78Zh9Q</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>0</td>\n",
       "      <td>Beautiful restoration.</td>\n",
       "      <td>tip</td>\n",
       "      <td>MLQre1nvUtW-RqMTc4iC9A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date  likes  \\\n",
       "0  cE27W9VPgO88Qxe4ol6y_g 2013-04-18      0   \n",
       "1  mVHrayjG3uZ_RLHkLj-AMg 2013-01-06      1   \n",
       "2  KayYbHCt-RkbGcPdGOThNg 2013-12-03      0   \n",
       "3  KayYbHCt-RkbGcPdGOThNg 2015-07-08      0   \n",
       "4  1_lU0-eSWJCRvNGk78Zh9Q 2015-10-25      0   \n",
       "\n",
       "                                                text type  \\\n",
       "0                             Don't waste your time.  tip   \n",
       "1  Your GPS will not allow you to find this place...  tip   \n",
       "2                              Great drink specials!  tip   \n",
       "3  Friendly staff, good food, great beer selectio...  tip   \n",
       "4                             Beautiful restoration.  tip   \n",
       "\n",
       "                  user_id  \n",
       "0  -6rEfobYjMxpUWLNxszaxQ  \n",
       "1  EZ0r9dKKtEGVx2CdnowPCw  \n",
       "2  xb6zEQCw9I-Gl0g06e1KsQ  \n",
       "3  QawZN4PSW7ng_9SP7pjsVQ  \n",
       "4  MLQre1nvUtW-RqMTc4iC9A  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Your GPS will not allow you to find this place. Put Rankin police department in instead. They are directly across the street.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_df.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for normalising text data\n",
    "\n",
    "# Convert all words to lowercase, remove punctuation, tokenise and stem\n",
    "# and remove stopwords, threshold = 10%\n",
    "def norm_corpus(document):\n",
    "\n",
    "    # lowercase and remove symbols\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    doc_tokens = tokenizer.tokenize(document.lower())\n",
    "        \n",
    "    # remove stopwords\n",
    "    doc_tokens = [word for word in doc_tokens if word not in stopwords.words('english')]\n",
    "        \n",
    "    # stem words\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    doc_stem = [stemmer.stem(word) for word in doc_tokens]\n",
    "        \n",
    "    # make tokenised text one string\n",
    "    norm_doc = \" \".join(doc_stem)\n",
    "    \n",
    "    return norm_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for vectorise normalised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vectorise keywords from normalised text to vector including only nouns and adjectives\n",
    "def review_vector(norm_doc):\n",
    "\n",
    "    # select all words categorised as nouns or adjectives\n",
    "    # loop through each string i.e. review in the df column\n",
    "    review_keyword_list = []\n",
    "    doc = nltk.word_tokenize(norm_doc)\n",
    "\n",
    "    # create tuple for each word in list: (word, tag)\n",
    "    token_category = nltk.pos_tag(doc)  \n",
    "\n",
    "    for word, tag in token_category:   \n",
    "            \n",
    "        # nouns\n",
    "        if (tag == 'NN' or tag == 'NNS' or tag == 'NNP' or tag == 'NNPS'):\n",
    "            review_keyword_list.append(word)\n",
    "                \n",
    "        # adjectives\n",
    "        elif (tag == 'JJ' or tag == 'JJS' or tag == 'JJP' or tag == 'JJPS'):\n",
    "            review_keyword_list.append(word)\n",
    "        \n",
    "        else:\n",
    "            pass     \n",
    "        \n",
    "    review_keywords = \" \".join(review_keyword_list)\n",
    "        \n",
    "    # vectorise string\n",
    "    WORD = re.compile(r'\\w+')\n",
    "    review_vector = Counter(WORD.findall(review_keywords))\n",
    "    \n",
    "    \n",
    "    return review_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tip text normalised, next: vectorise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>-6rEfobYjMxpUWLNxszaxQ</td>\n",
       "      <td>2013-04-18</td>\n",
       "      <td>{u'wast': 1, u'time': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>EZ0r9dKKtEGVx2CdnowPCw</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>{u'depart': 1, u'polic': 1, u'rankin': 1, u'di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>xb6zEQCw9I-Gl0g06e1KsQ</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>{u'great': 1, u'special': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>QawZN4PSW7ng_9SP7pjsVQ</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>{u'great': 1, u'good': 1, u'food': 1, u'beer':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_lU0-eSWJCRvNGk78Zh9Q</td>\n",
       "      <td>MLQre1nvUtW-RqMTc4iC9A</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>{u'beauti': 1, u'restor': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id       date  \\\n",
       "0  cE27W9VPgO88Qxe4ol6y_g  -6rEfobYjMxpUWLNxszaxQ 2013-04-18   \n",
       "1  mVHrayjG3uZ_RLHkLj-AMg  EZ0r9dKKtEGVx2CdnowPCw 2013-01-06   \n",
       "2  KayYbHCt-RkbGcPdGOThNg  xb6zEQCw9I-Gl0g06e1KsQ 2013-12-03   \n",
       "3  KayYbHCt-RkbGcPdGOThNg  QawZN4PSW7ng_9SP7pjsVQ 2015-07-08   \n",
       "4  1_lU0-eSWJCRvNGk78Zh9Q  MLQre1nvUtW-RqMTc4iC9A 2015-10-25   \n",
       "\n",
       "                                                 tip  \n",
       "0                           {u'wast': 1, u'time': 1}  \n",
       "1  {u'depart': 1, u'polic': 1, u'rankin': 1, u'di...  \n",
       "2                       {u'great': 1, u'special': 1}  \n",
       "3  {u'great': 1, u'good': 1, u'food': 1, u'beer':...  \n",
       "4                       {u'beauti': 1, u'restor': 1}  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = bus_df[['business_id', 'user_id', 'date']]\n",
    "output_df['tip'] = bus_df.text.apply(lambda x: norm_corpus(x))\n",
    "print \"tip text normalised, next: vectorise\"\n",
    "output_df.tip = output_df.tip.apply(lambda x: review_vector(x))\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output_df = bus_df[['business_id', 'user_id', 'date', 'stars', 'votes']]\n",
    "# output_df['review'] = norm_corpus(bus_df.text)\n",
    "# print \"review text normalised, next: vectorise\"\n",
    "# output_df.review = review_vector(output_df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
