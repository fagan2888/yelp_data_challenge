{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Read data file into a python array\n",
    "with open('../data/test_tip.json', 'rb') as f:\n",
    "    bus_data = f.readlines()\n",
    "\n",
    "# remove the trailing \"\\n\" from each line\n",
    "bus_data = map(lambda x: x.rstrip(), bus_data)\n",
    "# put individual business JSON objects into list\n",
    "data_json = \"[\" + ','.join(bus_data) + \"]\"\n",
    "\n",
    "# Create pandas df\n",
    "bus_df = pd.read_json(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>2013-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Don't waste your time.</td>\n",
       "      <td>tip</td>\n",
       "      <td>-6rEfobYjMxpUWLNxszaxQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Your GPS will not allow you to find this place...</td>\n",
       "      <td>tip</td>\n",
       "      <td>EZ0r9dKKtEGVx2CdnowPCw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>0</td>\n",
       "      <td>Great drink specials!</td>\n",
       "      <td>tip</td>\n",
       "      <td>xb6zEQCw9I-Gl0g06e1KsQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>0</td>\n",
       "      <td>Friendly staff, good food, great beer selectio...</td>\n",
       "      <td>tip</td>\n",
       "      <td>QawZN4PSW7ng_9SP7pjsVQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_lU0-eSWJCRvNGk78Zh9Q</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>0</td>\n",
       "      <td>Beautiful restoration.</td>\n",
       "      <td>tip</td>\n",
       "      <td>MLQre1nvUtW-RqMTc4iC9A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date  likes  \\\n",
       "0  cE27W9VPgO88Qxe4ol6y_g 2013-04-18      0   \n",
       "1  mVHrayjG3uZ_RLHkLj-AMg 2013-01-06      1   \n",
       "2  KayYbHCt-RkbGcPdGOThNg 2013-12-03      0   \n",
       "3  KayYbHCt-RkbGcPdGOThNg 2015-07-08      0   \n",
       "4  1_lU0-eSWJCRvNGk78Zh9Q 2015-10-25      0   \n",
       "\n",
       "                                                text type  \\\n",
       "0                             Don't waste your time.  tip   \n",
       "1  Your GPS will not allow you to find this place...  tip   \n",
       "2                              Great drink specials!  tip   \n",
       "3  Friendly staff, good food, great beer selectio...  tip   \n",
       "4                             Beautiful restoration.  tip   \n",
       "\n",
       "                  user_id  \n",
       "0  -6rEfobYjMxpUWLNxszaxQ  \n",
       "1  EZ0r9dKKtEGVx2CdnowPCw  \n",
       "2  xb6zEQCw9I-Gl0g06e1KsQ  \n",
       "3  QawZN4PSW7ng_9SP7pjsVQ  \n",
       "4  MLQre1nvUtW-RqMTc4iC9A  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Your GPS will not allow you to find this place. Put Rankin police department in instead. They are directly across the street.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bus_df.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            wast time\n",
       "1    gps allow find place put rankin polic depart i...\n",
       "2                                  great drink special\n",
       "3    friend staff good food great beer select relax...\n",
       "4                                        beauti restor\n",
       "5                           home stage 62 theatr group\n",
       "6                                   god send gear head\n",
       "7                  great peopl great servic alway busi\n",
       "8    sarah rock best waitress sure get compliment g...\n",
       "9                                          unlead 3 42\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper functions for normalising text data\n",
    "\n",
    "# Convert all words to lowercase, remove punctuation, tokenise and stem\n",
    "# and remove stopwords, threshold = 10%\n",
    "def norm_corpus(document):\n",
    "\n",
    "    # lowercase and remove symbols\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    doc_tokens = tokenizer.tokenize(document.lower())\n",
    "        \n",
    "    # remove stopwords\n",
    "    doc_tokens = [word for word in doc_tokens if word not in stopwords.words('english')]\n",
    "        \n",
    "    # stem words\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    doc_stem = [stemmer.stem(word) for word in doc_tokens]\n",
    "        \n",
    "    # make tokenised text one string\n",
    "    norm_doc = \" \".join(doc_stem)\n",
    "    \n",
    "    return norm_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for vectorise normalised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({u'g': 1}),\n",
       " Counter({u'p': 1}),\n",
       " Counter({u's': 1}),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter({u'l': 1}),\n",
       " Counter({u'l': 1}),\n",
       " Counter({u'o': 1}),\n",
       " Counter({u'w': 1}),\n",
       " Counter(),\n",
       " Counter({u'f': 1}),\n",
       " Counter({u'i': 1}),\n",
       " Counter({u'n': 1}),\n",
       " Counter({u'd': 1}),\n",
       " Counter(),\n",
       " Counter({u'p': 1}),\n",
       " Counter({u'l': 1}),\n",
       " Counter(),\n",
       " Counter({u'c': 1}),\n",
       " Counter({u'e': 1}),\n",
       " Counter(),\n",
       " Counter({u'p': 1}),\n",
       " Counter({u'u': 1}),\n",
       " Counter({u't': 1}),\n",
       " Counter(),\n",
       " Counter({u'r': 1}),\n",
       " Counter(),\n",
       " Counter({u'n': 1}),\n",
       " Counter({u'k': 1}),\n",
       " Counter({u'i': 1}),\n",
       " Counter({u'n': 1}),\n",
       " Counter(),\n",
       " Counter({u'p': 1}),\n",
       " Counter({u'o': 1}),\n",
       " Counter({u'l': 1}),\n",
       " Counter({u'i': 1}),\n",
       " Counter({u'c': 1}),\n",
       " Counter(),\n",
       " Counter({u'd': 1}),\n",
       " Counter({u'e': 1}),\n",
       " Counter({u'p': 1}),\n",
       " Counter(),\n",
       " Counter({u'r': 1}),\n",
       " Counter({u't': 1}),\n",
       " Counter(),\n",
       " Counter({u'i': 1}),\n",
       " Counter({u'n': 1}),\n",
       " Counter({u's': 1}),\n",
       " Counter({u't': 1}),\n",
       " Counter({u'e': 1}),\n",
       " Counter(),\n",
       " Counter({u'd': 1}),\n",
       " Counter(),\n",
       " Counter({u'd': 1}),\n",
       " Counter({u'i': 1}),\n",
       " Counter({u'r': 1}),\n",
       " Counter({u'e': 1}),\n",
       " Counter({u'c': 1}),\n",
       " Counter({u't': 1}),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter({u'c': 1}),\n",
       " Counter({u'r': 1}),\n",
       " Counter({u'o': 1}),\n",
       " Counter({u's': 1}),\n",
       " Counter({u's': 1}),\n",
       " Counter(),\n",
       " Counter({u's': 1}),\n",
       " Counter({u't': 1}),\n",
       " Counter({u'r': 1}),\n",
       " Counter({u'e': 1}),\n",
       " Counter({u'e': 1}),\n",
       " Counter({u't': 1})]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorise keywords from normalised text to vector including only nouns and adjectives\n",
    "def review_vector(norm_doc):\n",
    "    review_list = []\n",
    "\n",
    "    # select all words categorised as nouns or adjectives\n",
    "    # loop through each string i.e. review in the df column\n",
    "    for doc in norm_doc_list:\n",
    "        review_keyword_list = []\n",
    "        doc = nltk.word_tokenize(doc)\n",
    "        # create tuple for each word in list: (word, tag)\n",
    "        token_category = nltk.pos_tag(doc)\n",
    "        \n",
    "        \n",
    "        for word, tag in token_category:    \n",
    "            \n",
    "            # nouns\n",
    "            if (tag == 'NN' or tag == 'NNS' or tag == 'NNP' or tag == 'NNPS'):\n",
    "                review_keyword_list.append(word)\n",
    "                \n",
    "            # adjectives\n",
    "            elif (tag == 'JJ' or tag == 'JJS' or tag == 'JJP' or tag == 'JJPS'):\n",
    "                review_keyword_list.append(word)\n",
    "            else:\n",
    "                pass     \n",
    "        \n",
    "        review_keywords = \" \".join(review_keyword_list)\n",
    "        review_list.append(review_keywords)\n",
    "        \n",
    "        # vectorise string\n",
    "        WORD = re.compile(r'\\w+')\n",
    "        review_vector = [Counter(WORD.findall(word)) for word in review_list]\n",
    "    \n",
    "    \n",
    "    return review_vector\n",
    "    \n",
    "output_df = bus_df.copy()\n",
    "output_df.text = output_df.text.apply(lambda x: norm_corpus(x))\n",
    "output_df.text = output_df.text.apply(lambda x: review_vector(x))\n",
    "output_df.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>-6rEfobYjMxpUWLNxszaxQ</td>\n",
       "      <td>2013-04-18</td>\n",
       "      <td>{u'wast': 1, u'time': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>EZ0r9dKKtEGVx2CdnowPCw</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>{u'depart': 1, u'polic': 1, u'rankin': 1, u'di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>xb6zEQCw9I-Gl0g06e1KsQ</td>\n",
       "      <td>2013-12-03</td>\n",
       "      <td>{u'great': 1, u'special': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KayYbHCt-RkbGcPdGOThNg</td>\n",
       "      <td>QawZN4PSW7ng_9SP7pjsVQ</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>{u'great': 1, u'good': 1, u'food': 1, u'beer':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_lU0-eSWJCRvNGk78Zh9Q</td>\n",
       "      <td>MLQre1nvUtW-RqMTc4iC9A</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>{u'beauti': 1, u'restor': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_lU0-eSWJCRvNGk78Zh9Q</td>\n",
       "      <td>bvu13GyOUwhEjPum2xjiqQ</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>{u'home': 1, u'theatr': 1, u'group': 1, u'stag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_qopVQ6_Mz6W7-Pmbi56GQ</td>\n",
       "      <td>bvu13GyOUwhEjPum2xjiqQ</td>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>{u'god': 1, u'head': 1, u'send': 1, u're': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_qopVQ6_Mz6W7-Pmbi56GQ</td>\n",
       "      <td>_QFom7aSHKNCDsNXKd-3xQ</td>\n",
       "      <td>2010-08-27</td>\n",
       "      <td>{u'peopl': 1, u'great': 2, u'busi': 1, u'servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wJr6kSA5dchdgOdwH6dZ2w</td>\n",
       "      <td>fvTivrsJoUMYXnOJw9wZfw</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>{u'sarah': 1, u'sure': 1, u'best': 1, u'glass'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cdcus0NADzyY3XiJM2O5Sg</td>\n",
       "      <td>bvu13GyOUwhEjPum2xjiqQ</td>\n",
       "      <td>2011-10-12</td>\n",
       "      <td>{u'unlead': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id       date  \\\n",
       "0  cE27W9VPgO88Qxe4ol6y_g  -6rEfobYjMxpUWLNxszaxQ 2013-04-18   \n",
       "1  mVHrayjG3uZ_RLHkLj-AMg  EZ0r9dKKtEGVx2CdnowPCw 2013-01-06   \n",
       "2  KayYbHCt-RkbGcPdGOThNg  xb6zEQCw9I-Gl0g06e1KsQ 2013-12-03   \n",
       "3  KayYbHCt-RkbGcPdGOThNg  QawZN4PSW7ng_9SP7pjsVQ 2015-07-08   \n",
       "4  1_lU0-eSWJCRvNGk78Zh9Q  MLQre1nvUtW-RqMTc4iC9A 2015-10-25   \n",
       "5  1_lU0-eSWJCRvNGk78Zh9Q  bvu13GyOUwhEjPum2xjiqQ 2015-01-06   \n",
       "6  _qopVQ6_Mz6W7-Pmbi56GQ  bvu13GyOUwhEjPum2xjiqQ 2013-02-13   \n",
       "7  _qopVQ6_Mz6W7-Pmbi56GQ  _QFom7aSHKNCDsNXKd-3xQ 2010-08-27   \n",
       "8  wJr6kSA5dchdgOdwH6dZ2w  fvTivrsJoUMYXnOJw9wZfw 2013-07-22   \n",
       "9  Cdcus0NADzyY3XiJM2O5Sg  bvu13GyOUwhEjPum2xjiqQ 2011-10-12   \n",
       "\n",
       "                                                 tip  \n",
       "0                           {u'wast': 1, u'time': 1}  \n",
       "1  {u'depart': 1, u'polic': 1, u'rankin': 1, u'di...  \n",
       "2                       {u'great': 1, u'special': 1}  \n",
       "3  {u'great': 1, u'good': 1, u'food': 1, u'beer':...  \n",
       "4                       {u'beauti': 1, u'restor': 1}  \n",
       "5  {u'home': 1, u'theatr': 1, u'group': 1, u'stag...  \n",
       "6      {u'god': 1, u'head': 1, u'send': 1, u're': 1}  \n",
       "7  {u'peopl': 1, u'great': 2, u'busi': 1, u'servi...  \n",
       "8  {u'sarah': 1, u'sure': 1, u'best': 1, u'glass'...  \n",
       "9                                     {u'unlead': 1}  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = bus_df[['business_id', 'user_id', 'date']]  \n",
    "output_df['tip'] = norm_corpus(bus_df.text)\n",
    "output_df.tip = review_vector(output_df.tip)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review text normalised, next: vectorise\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>votes</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>PUFPaY9KxDAcGqfsorJp3Q</td>\n",
       "      <td>2012-08-01</td>\n",
       "      <td>4</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'fashion': 1, u'old': 1, u'hoagi': 2, u'burg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>Iu6AxdBYGR4A0wspR9BYHA</td>\n",
       "      <td>2014-02-13</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'machin': 1, u'tradit': 1, u'use': 1, u'food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5UmKMjUEUNdYWqANhGckJw</td>\n",
       "      <td>auESFwWvW42h6alXgFxAXQ</td>\n",
       "      <td>2015-10-31</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'pennysav': 1, u'win': 1, u'realli': 1, u'se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>uK8tzraOp4M5u3uYrqIBXg</td>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'dine': 1, u'simpli': 1, u'at': 1, u'famili'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>I_47G-R2_egp7ME5u_ltew</td>\n",
       "      <td>2014-03-29</td>\n",
       "      <td>3</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'anytim': 1, u'item': 1, u'crispi': 1, u'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>PP_xoMSYlGr2pb67BbqBdA</td>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>1</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'butter': 1, u'water': 1, u'good': 2, u'mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>JPPhyFE-UE453zA6K0TVgw</td>\n",
       "      <td>2014-11-28</td>\n",
       "      <td>4</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'fish': 2, u'cheap': 1, u'sandwich': 1, u'ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3eu6MEFlq2Dg7bQh8QbdOg</td>\n",
       "      <td>2d5HeDvZTDUNVog_WuUpSg</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'issu': 1, u'realli': 1, u'high': 1, u'mecha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3eu6MEFlq2Dg7bQh8QbdOg</td>\n",
       "      <td>BShxMIUwaJS378xcrz4Nmg</td>\n",
       "      <td>2015-06-16</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'funny': 0, u'useful': 0, u'cool': 0}</td>\n",
       "      <td>{u'shop': 2, u'neighborhood': 1, u'fair': 1, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cE27W9VPgO88Qxe4ol6y_g</td>\n",
       "      <td>fhNxoMwwTipzjO8A9LFe8Q</td>\n",
       "      <td>2012-08-19</td>\n",
       "      <td>3</td>\n",
       "      <td>{u'funny': 0, u'useful': 1, u'cool': 0}</td>\n",
       "      <td>{u'rang': 3, u'golf': 1, u'close': 1, u'open':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id       date  stars  \\\n",
       "0  5UmKMjUEUNdYWqANhGckJw  PUFPaY9KxDAcGqfsorJp3Q 2012-08-01      4   \n",
       "1  5UmKMjUEUNdYWqANhGckJw  Iu6AxdBYGR4A0wspR9BYHA 2014-02-13      5   \n",
       "2  5UmKMjUEUNdYWqANhGckJw  auESFwWvW42h6alXgFxAXQ 2015-10-31      5   \n",
       "3  UsFtqoBl7naz8AVUBZMjQQ  uK8tzraOp4M5u3uYrqIBXg 2013-11-08      5   \n",
       "4  UsFtqoBl7naz8AVUBZMjQQ  I_47G-R2_egp7ME5u_ltew 2014-03-29      3   \n",
       "5  UsFtqoBl7naz8AVUBZMjQQ  PP_xoMSYlGr2pb67BbqBdA 2014-10-29      1   \n",
       "6  UsFtqoBl7naz8AVUBZMjQQ  JPPhyFE-UE453zA6K0TVgw 2014-11-28      4   \n",
       "7  3eu6MEFlq2Dg7bQh8QbdOg  2d5HeDvZTDUNVog_WuUpSg 2014-02-27      5   \n",
       "8  3eu6MEFlq2Dg7bQh8QbdOg  BShxMIUwaJS378xcrz4Nmg 2015-06-16      5   \n",
       "9  cE27W9VPgO88Qxe4ol6y_g  fhNxoMwwTipzjO8A9LFe8Q 2012-08-19      3   \n",
       "\n",
       "                                     votes  \\\n",
       "0  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "1  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "2  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "3  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "4  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "5  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "6  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "7  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "8  {u'funny': 0, u'useful': 0, u'cool': 0}   \n",
       "9  {u'funny': 0, u'useful': 1, u'cool': 0}   \n",
       "\n",
       "                                              review  \n",
       "0  {u'fashion': 1, u'old': 1, u'hoagi': 2, u'burg...  \n",
       "1  {u'machin': 1, u'tradit': 1, u'use': 1, u'food...  \n",
       "2  {u'pennysav': 1, u'win': 1, u'realli': 1, u'se...  \n",
       "3  {u'dine': 1, u'simpli': 1, u'at': 1, u'famili'...  \n",
       "4  {u'anytim': 1, u'item': 1, u'crispi': 1, u'res...  \n",
       "5  {u'butter': 1, u'water': 1, u'good': 2, u'mayb...  \n",
       "6  {u'fish': 2, u'cheap': 1, u'sandwich': 1, u'ho...  \n",
       "7  {u'issu': 1, u'realli': 1, u'high': 1, u'mecha...  \n",
       "8  {u'shop': 2, u'neighborhood': 1, u'fair': 1, u...  \n",
       "9  {u'rang': 3, u'golf': 1, u'close': 1, u'open':...  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = bus_df[['business_id', 'user_id', 'date', 'stars', 'votes']]\n",
    "output_df['review'] = norm_corpus(bus_df.text)\n",
    "print \"review text normalised, next: vectorise\"\n",
    "output_df.review = review_vector(output_df.review)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "document = \"string. With. Punctuation?\"\n",
    "doc = document.translate(string.maketrans(\"\",\"\"), string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'annoying th'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer = SnowballStemmer('english')\n",
    "test = tokenizer.tokenize('hello there hi')\n",
    "snowball_stemmer.stem('annoying things')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
